{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a748876-39e2-4b69-bda4-76b36e17f4cd",
   "metadata": {},
   "source": [
    "# Init Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593929d",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40677a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note of the module installations\n",
    "# install python with pyenv (ref: https://github.com/lewagon/data-setup/blob/e5a239926f304d452704718136b6e2f017c7303d/macOS.md#installing-python-with-pyenv)\n",
    "# setup virtual environment with pyenv (ref:https://github.com/lewagon/data-setup/blob/e5a239926f304d452704718136b6e2f017c7303d/macOS.md#installing-python-with-pyenv\n",
    "# error: 'Failed to activate virtualenv' (ref:https://github.com/pyenv/pyenv-virtualenv/issues/387)\n",
    "# pip install fasttext (0.9.2) (after installing the dependencies: numpy, scipy, pybind11, setuptools, wheel)\n",
    "\n",
    "# install Jupyter notebook and nbextensions (ref: https://github.com/lewagon/data-setup/blob/e5a239926f304d452704718136b6e2f017c7303d/macOS.md#jupyter-notebook-extensions)\n",
    "#   pip install jupyter_contrib_nbextensions\n",
    "#   pip install --upgrade notebook==6.4.12 (ref:https://stackoverflow.com/questions/49647705/jupyter-nbextensions-does-not-appear)\n",
    "#   pip install traitlets==5.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b937898",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bfc6d8-5b16-46c7-9c7d-20d869a41ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T09:32:43.980824Z",
     "start_time": "2023-10-16T09:32:42.963982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from config import *\n",
    "\n",
    "from src.helper_visualization import *\n",
    "from src.helper_text import *\n",
    "from src.helper_language import *\n",
    "from src.helper_translation import *\n",
    "from src.helper_pred import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2ebf9-1e49-48b3-9989-ea190f96d532",
   "metadata": {},
   "source": [
    "# Combine Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "files = glob.glob(f'{DATA_FOLDER_PATH_RAW}/data_202*.xlsx')\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file and read it into a DataFrame\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, index_col=None)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into one\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965d317-641f-4700-b460-d36276bbcc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "df_combined.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2692b71-70f9-4567-a213-a003b05f085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which have large number of null values will be dropped \n",
    "columns_to_drop = [\n",
    "    'Escalated To Engineering', \n",
    "    'Bug Type', \n",
    "    'Status Reason', \n",
    "    'Escalated to L2',\n",
    "    'Category',\n",
    "    'Completion Code'\n",
    "]\n",
    "try: \n",
    "    df_combined.drop(columns_to_drop, axis=1, inplace = True)\n",
    "    df_combined.dropna(subset=['Request ID'], inplace=True)\n",
    "    df_combined.dropna(subset=['Product Name'], inplace=True)\n",
    "    df_combined.dropna(subset=['Title'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "# surprisingly, there are over 100k duplications\n",
    "df_combined.drop_duplicates(subset=['Title', 'Product Name'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426248b-15ce-4d37-a870-a69b17c67d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name and path\n",
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_combined.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_combined.to_excel(excel_file, index=False)  # Set index to False if you don't want to export the DataFrame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c2d47-3a46-4ccf-8d26-625ce2dca9b0",
   "metadata": {},
   "source": [
    "# Load Data for Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9700383-1461-49d3-86c4-4989b4a8817f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-16T09:33:28.968Z"
    }
   },
   "outputs": [],
   "source": [
    "data_url = f'{DATA_FOLDER_PATH_PROCESSED}/data_combined.xlsx'\n",
    "df_combined = pd.read_excel(data_url, index_col=None)\n",
    "print(df_combined.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19545faf-1ce2-44df-9920-6d40fd68764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_combined.copy()\n",
    "df_processed['Length'] = 0\n",
    "df_processed['Language']=pd.NA\n",
    "df_processed['Title_Processed']=pd.NA\n",
    "df_processed['Title_Translated']=pd.NA\n",
    "df_processed['Title_Cleaned']=pd.NA\n",
    "print(df_processed.info())\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457b308",
   "metadata": {},
   "source": [
    "# Cleanup Product Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee746ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_labels(df_processed, 'Product Name', log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Module Name to replace Product Name for all 'Petrotechnical Suite - Domain Profiles'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Petrotechnical Suite - Domain Profiles', 'Product Name'] = df_processed['Module Name']\n",
    "df_processed.drop(columns=['Module Name'], inplace=True)\n",
    "df_processed.dropna(subset=['Product Name'], inplace=True)\n",
    "\n",
    "# Consolidate the following products into Petrel\n",
    "df_processed.loc[df_processed['Product Name'] == 'Petrel Exploration Geology', 'Product Name'] = 'Petrel'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Petrel Project Explorer', 'Product Name'] = 'Petrel'\n",
    "\n",
    "# Case of one product has multiple names\n",
    "df_processed.loc[df_processed['Product Name'] == 'DELFI RE', 'Product Name'] = 'Petrel RE' # Pretel RE --> DELFI RE\n",
    "df_processed.loc[df_processed['Product Name'] == 'OMEGA', 'Product Name'] = 'Omega' # OMEGA --> Omega\n",
    "df_processed.loc[df_processed['Product Name'] == 'Other', 'Product Name'] = 'Others' # Other --> Others\n",
    "df_processed.loc[df_processed['Product Name'] == 'Third-Party Applications', 'Product Name'] = 'App – Third Party' # Third-Party Applications --> App – Third Party\n",
    "df_processed.loc[df_processed['Product Name'] == 'Ocean Plug-ins for Petrel - Third party', 'Product Name'] = 'Ocean Plug-ins for Petrel - Third Party' # Ocean Plug-ins for Petrel - Third party --> Ocean Plug-ins for Petrel - Third Party\n",
    "\n",
    "# Consolidate the following products into 'Deployment'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Provisioning & Decommissioning', 'Product Name'] = 'Deployment'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Software Demo and Evaluation', 'Product Name'] = 'Deployment'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Internal Deployment', 'Product Name'] = 'Deployment'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Image', 'Product Name'] = 'Deployment'\n",
    "\n",
    "# Consolidate the following products into 'Delfi Portal'\n",
    "df_processed.loc[df_processed['Product Name'] == 'SAuth', 'Product Name'] = 'Delfi Portal'\n",
    "df_processed.loc[df_processed['Product Name'] == 'License', 'Product Name'] = 'Delfi Portal'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Licensing', 'Product Name'] = 'Delfi Portal'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Environment', 'Product Name'] = 'Delfi Portal'\n",
    "df_processed.loc[df_processed['Product Name'] == 'Authorization', 'Product Name'] = 'Delfi Portal'\n",
    "\n",
    "#drop the rows which Product Name is 'Quality and Feedback' and 'Software Training Services'\n",
    "df_processed = df_processed[df_processed['Product Name'] != 'Quality and Feedback']\n",
    "df_processed = df_processed[df_processed['Product Name'] != 'Software Training Services']\n",
    "\n",
    "#Drop the products which have less than 50 records\n",
    "df_processed = df_processed.groupby('Product Name').filter(lambda x : len(x)>50)\n",
    "\n",
    "print(df_processed.info())\n",
    "hist_by_labels(df_processed, 'Product Name', top=None, log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd684eca-5c11-4f08-b9f7-41e62f596f3a",
   "metadata": {},
   "source": [
    "# Clean-up Title Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c91b8",
   "metadata": {},
   "source": [
    "## Quick Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063ed32-3753-44c6-84f0-b3a50abf3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows to process\n",
    "num = df_processed['Title'].notnull().sum()\n",
    "\n",
    "# Initialize a progress bar with the total number of rows\n",
    "progress_bar = tqdm(total=num, desc=\"Processing Rows\", unit=\" row\")\n",
    "\n",
    "# Function to process a single row and update the 'Processed_Title' column\n",
    "def process_row(index):\n",
    "    # processed_title = preprocess_step_1(df_combined.at[index, 'Title'])\n",
    "    processed_title = quick_clean_up(df_processed.at[index, 'Title'])\n",
    "    df_processed.at[index, 'Title_Processed'] = processed_title\n",
    "    df_processed.at[index, 'Length'] = len(processed_title)\n",
    "#     df.at[index, 'Language'] = detect_language_fasttext(processed_title)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Define the number of parallel workers (adjust this based on your CPU cores)\n",
    "num_workers = 8\n",
    "\n",
    "# Create a ThreadPoolExecutor with the specified number of workers\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use the executor to process rows in parallel\n",
    "    executor.map(process_row, df_processed.index)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f25b0-f751-4bc8-9b3f-bc9d7b284de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete records with missing values in 'ProductName' columns\n",
    "df_processed.dropna(subset=['Title_Processed'], inplace=True)\n",
    "# Remove duplicates based on 'Title' and 'ProductName' columns\n",
    "df_processed.drop_duplicates(subset=['Title_Processed', 'Product Name'], keep='first', inplace=True)\n",
    "\n",
    "print(df_processed.info())\n",
    "hist_by_labels(df_processed, 'Length', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427ff81-089a-4939-8b2c-6aed1ddbe219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows to process\n",
    "num = df_processed['Title_Processed'].notnull().sum()\n",
    "\n",
    "# df['Title_Translated'] = df['Title_Processed']\n",
    "# Initialize a progress bar with the total number of rows\n",
    "progress_bar = tqdm(total=num, desc=\"Processing Rows\", unit=\" row\")\n",
    "\n",
    "# Function to process a single row and update the 'Processed_Title' column\n",
    "def process_row(index):\n",
    "    df_processed.at[index, 'Language'] = detect_language_fasttext(df_processed.at[index, 'Title_Processed'])\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Define the number of parallel workers (adjust this based on your CPU cores)\n",
    "num_workers = 8\n",
    "\n",
    "# Create a ThreadPoolExecutor with the specified number of workers\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use the executor to process rows in parallel\n",
    "    executor.map(process_row, df_processed.index)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ce998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext performance is better than the other solutions for short text \n",
    "# (ref: https://medium.com/besedo-engineering/language-identification-for-very-short-texts-a-review-c9f2756773ad\n",
    "\n",
    "hist_by_labels(df_processed, \"Language\", log=True, horizontal=True, left=10.5)\n",
    "hist_by_labels(df_processed, \"Language\", top=20, log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820dda9-d136-4da6-8022-1459bd7b1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name and path\n",
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_processed.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_processed.to_excel(excel_file, index=False)  # Set index to False if you don't want to export the DataFrame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846983c-24de-4541-b3ea-6a710ad7ed3d",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4e4ec-7a98-4c29-b17b-98b032b563f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_processed.xlsx'\n",
    "df_processed = pd.read_excel(excel_file)\n",
    "\n",
    "df_translated = df_processed.copy()\n",
    "df_translated['Title_Translated'] = df_translated['Title_Processed']\n",
    "print(df_translated.info())\n",
    "df_translated.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8b44c-7e70-44e7-af70-e729bf0fe747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the top 10 languages and drop the rest and the unknown. \n",
    "# why? There are high chances the detected language were not correct due to wrong spelling, etc.\n",
    "\n",
    "language_counts = df_translated['Language'].value_counts()\n",
    "cutoff = 99\n",
    "language_others = language_counts.index[language_counts < cutoff]\n",
    "\n",
    "mask_others = df_translated['Language'].isin(language_others)\n",
    "df_translated.loc[mask_others,'Language']='unknown'\n",
    "\n",
    "# Drop rows where 'Language' is equal to 'unknown'\n",
    "df_translated = df_translated[df_translated['Language'] != 'unknown']\n",
    "print(df_translated.info())\n",
    "hist_by_labels(df_translated, 'Language', log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92575d-7fd5-4e8b-9e23-d67726c396d3",
   "metadata": {},
   "source": [
    "## Translation of Non-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd9679-e4cf-47d2-a77e-32e972bd5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by the \"Language\" column\n",
    "grouped = df_translated.groupby(\"Language\")\n",
    "\n",
    "# Initialize tqdm to display progress bar\n",
    "pbar = tqdm(total=len(grouped), desc=f\"Processing\")\n",
    "\n",
    "# Create an empty list to store the processed groups\n",
    "processed_groups = []\n",
    "\n",
    "# Iterate through sub DataFrames\n",
    "for lang, group in grouped:\n",
    "    pbar.set_description(f\"Processing [{lang}/{len(group)}]\")\n",
    "\n",
    "    if lang != \"en\": # Skip English\n",
    "        translated_titles = translate_array_to_english(\n",
    "            group[\"Title_Translated\"].tolist(),\n",
    "            src_lang=lang,\n",
    "            length_limit=1250)\n",
    "        group[\"Title_Translated\"] = translated_titles  # Update \"Title_Translated\" column in the group\n",
    "    \n",
    "    processed_groups.append(group)\n",
    "    pbar.update(1)  # Update the progress bar\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Concatenate the groups back into a single DataFrame\n",
    "df_translated = pd.concat(processed_groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fba62-05b6-4e40-a7e0-8e03657d3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_translated.isnull().sum().sort_values(ascending = False))\n",
    "\n",
    "# Delete records with missing values in 'ProductName' columns\n",
    "df_translated.dropna(subset=['Title_Translated'], inplace=True)\n",
    "# Remove duplicates based on 'Title' and 'ProductName' columns\n",
    "df_translated.drop_duplicates(subset=['Title_Processed', 'Product Name'], keep='first', inplace=True)\n",
    "print(df_translated.info())\n",
    "hist_by_labels(df_translated, 'Language', log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab544da-93a1-4c0a-86a6-b72e12a69354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name and path\n",
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_translated.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_translated.to_excel(excel_file, index=False)  # Set index to False if you don't want to export the DataFrame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3537a-faa7-4f48-95cc-0dfc113b2790",
   "metadata": {},
   "source": [
    "## Final Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27eae32-4326-42a0-aebe-9c0d61619e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_translated.xlsx'\n",
    "\n",
    "df_cleaned = pd.read_excel(excel_file , dtype={'Request ID': str, 'Title_Cleaned': str})\n",
    "print(df_cleaned.info())\n",
    "print(df_cleaned.info())\n",
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479466a3-ecbf-46a2-bbfe-2ffca4d83b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop(columns=[\n",
    "    'Created Time', \n",
    "    'Customer Company', 'Customer Country', \n",
    "    'Priority', 'Urgency', 'Impact', \n",
    "    'Service Definition', 'Service Desk Group', 'Status',\n",
    "    'Closed Time', \n",
    "    'Response Time (Min)', 'Resolution Time (Min)', \n",
    "    'Contracts Reference', 'Creation Source'\n",
    "    ], inplace=True)\n",
    "\n",
    "# Set the number of rows to process\n",
    "num = df_cleaned['Title_Translated'].notnull().sum()\n",
    "\n",
    "# Initialize a progress bar with the total number of rows\n",
    "progress_bar = tqdm(total=num, desc=\"Processing Rows\", unit=\" row\")\n",
    "\n",
    "# Function to process a single row and update the 'Processed_Title' column\n",
    "def process_row(index):\n",
    "    df_cleaned.at[index, 'Title_Cleaned'] = final_clean_up(df_cleaned.at[index, 'Title_Translated'])\n",
    "    df_cleaned.at[index, 'Length'] = count_words(df_cleaned.at[index, 'Title_Cleaned'])\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Define the number of parallel workers (adjust this based on your CPU cores)\n",
    "num_workers = 8\n",
    "\n",
    "# Create a ThreadPoolExecutor with the specified number of workers\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Use the executor to process rows in parallel\n",
    "    executor.map(process_row, df_cleaned.index)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c85b7-d6e1-44ed-987f-49d83685d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on 'Title' and 'ProductName' columns after translation\n",
    "df_cleaned.dropna(subset=['Title_Cleaned'], inplace=True)\n",
    "df_cleaned.drop_duplicates(subset=['Title_Processed', 'Product Name'], keep='first', inplace=True)\n",
    "print(df_cleaned.info())\n",
    "\n",
    "# remove the same title pointing to multiple products\n",
    "n_title = df_cleaned['Title_Cleaned'].value_counts()\n",
    "good_title = n_title.index[n_title == 1]\n",
    "print (len(good_title))\n",
    "\n",
    "mask = df_cleaned['Title_Cleaned'].isin(good_title)\n",
    "df_cleaned = df_cleaned[mask]\n",
    "print(df_cleaned.info())\n",
    "print(df_cleaned.isnull().sum().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0799c-9838-4762-b4df-60b3df6b6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name and path\n",
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_cleaned.xlsx'\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "df_cleaned.to_excel(excel_file, index=False)  # Set index to False if you don't want to export the DataFrame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a409684",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafea36",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cee41b",
   "metadata": {},
   "source": [
    "### Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d43cb-9c69-4ee3-af91-93d06408057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_cleaned.xlsx'\n",
    "df_cleaned = pd.read_excel(excel_file)\n",
    "print(df_cleaned.info())\n",
    "hist_by_labels(df_cleaned, 'Length', log=False, left=2.5, right=15.5)\n",
    "# plot a square in red color on the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05769ab9",
   "metadata": {},
   "source": [
    "### Remove short Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa6138-b8e2-409b-9671-f4c6cbeacae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the titles with length less than 3 and more than 20\n",
    "# when the title is too short, it is either not useful or it is too obvious to be classified\n",
    "mask = (df_cleaned['Length'] > 3) & (df_cleaned['Length'] < 20)\n",
    "df_cleaned = df_cleaned[mask]\n",
    "hist_by_labels(df_cleaned, 'Length', horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af51ac",
   "metadata": {},
   "source": [
    "### Combine the long tail into Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af37490",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_labels(df_cleaned, 'Product Name', top=26, log=True, horizontal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f2f21-a4f0-4737-86d1-240d5b879bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the top 50 products and combine the rest into 'Others'\n",
    "product_counts = df_cleaned['Product Name'].value_counts()\n",
    "cutoff = 400\n",
    "product_top = product_counts.index[product_counts >= cutoff]\n",
    "product_others = product_counts.index[product_counts < cutoff]\n",
    "\n",
    "mask_others = df_cleaned['Product Name'].isin(product_others)\n",
    "df_cleaned.loc[mask_others,'Product Name']='Others'\n",
    "hist_by_labels(df_cleaned, 'Product Name', log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfd88b",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea87d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the products with more than 5000 records, randomly select 4000 records for each product and put in a new dataframe df_cleaned_balanced, then keep the rest of the records in df_cleaned_test\n",
    "df_cleaned_balanced = pd.DataFrame()\n",
    "df_cleaned_test = pd.DataFrame()\n",
    "for product in df_cleaned['Product Name'].unique():\n",
    "    df_product = df_cleaned[df_cleaned['Product Name'] == product]\n",
    "    if df_product.shape[0] > 5000:\n",
    "        df_product_balanced = df_product.sample(4000).copy()\n",
    "        df_cleaned_balanced = pd.concat([df_cleaned_balanced, df_product_balanced])\n",
    "        df_product_test = df_product.drop(df_product_balanced.index)\n",
    "        df_cleaned_test = pd.concat([df_cleaned_test, df_product_test])\n",
    "    else:\n",
    "        df_product_balanced = df_product.sample(frac=0.8).copy()\n",
    "        df_cleaned_balanced = pd.concat([df_cleaned_balanced, df_product_balanced])\n",
    "        df_product_test = df_product.drop(df_product_balanced.index)\n",
    "        df_cleaned_test = pd.concat([df_cleaned_test, df_product_test])\n",
    "\n",
    "print(df_cleaned_balanced.info())\n",
    "print(df_cleaned_test.info())\n",
    "\n",
    "hist_by_labels(df_cleaned_balanced, 'Product Name', log=True)\n",
    "hist_by_labels(df_cleaned_test, 'Product Name', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496df7d-bb58-48ec-8549-b32d385a358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and testing for \n",
    "# a. cross validation\n",
    "# b. logistic regression, \n",
    "# c. SGC Classifier\n",
    "\n",
    "#import packages related to data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = df_cleaned['Title_Cleaned']\n",
    "vectorizer = CountVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X_train = df_cleaned_balanced['Title_Cleaned']\n",
    "X_train_encoded = vectorizer.transform(X_train)\n",
    "y_train = df_cleaned_balanced['Product Name']\n",
    "\n",
    "X_test = df_cleaned_test['Title_Cleaned']\n",
    "X_test_encoded = vectorizer.transform(X_test)\n",
    "y_test = df_cleaned_test['Product Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ee214-7530-4cbb-a8ef-c2f414d67a5c",
   "metadata": {},
   "source": [
    "## Model Baseline - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311dbb7-0451-4146-a451-2c7bd139af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Tuning\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdb179-508b-45f5-9951-94d9ee1b4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'SGDClassifier': SGDClassifier(max_iter=5000),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=5000),\n",
    "    'SVC rbf': SVC(kernel='rbf'),\n",
    "    'SVC linear': SVC(kernel='linear'),\n",
    "    # 'RandomForestClassifier': RandomForestClassifier(),\n",
    "    # 'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    # 'XGBClassifier': xgb.XGBClassifier()\n",
    "}\n",
    "\n",
    "print('Baseline Score(s) of each model are ....')\n",
    "\n",
    "for model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        models[model], \n",
    "        X_train_encoded, # please provide the features after preprocessing\n",
    "        y_train, #the target\n",
    "        cv=5, \n",
    "        scoring='accuracy', # lease revise to the appropriate score\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f'Average score: \\033[94m{\"{:.4f}\".format(np.mean(cv_result))}\\033[0m by \\033[94m{model}\\033[0m.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12256a",
   "metadata": {},
   "source": [
    "# Hpyerparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916dcf5",
   "metadata": {},
   "source": [
    "## SGC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd268f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'loss': trial.suggest_categorical('loss', ['log_loss', 'modified_huber']),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e+2, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'max_iter': 5000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    sgd_classifier = SGDClassifier(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(sgd_classifier, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_sgc = SGDClassifier(**best_params)\n",
    "best_model_sgc.fit(X_train_encoded, y_train)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict categories for the test data\n",
    "y_pred_sgc = best_model_sgc.predict(X_test_encoded)\n",
    "# Evaluate the classifier's performance\n",
    "print(classification_report(y_test, y_pred_sgc, digits=3))\n",
    "plot_confusion_matrix(y_test, y_pred_sgc, title='Confusion matrix for Rests')\n",
    "df_pred_top5_sgc = top5_accuracy_report(best_model_sgc, vectorizer, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "import pickle\n",
    "pickle.dump(best_model_sgc, open(f'{MODEL_FOLDER_PATH}/model_sgc_classifier.pkl', 'wb'))\n",
    "\n",
    "# export the vectorizer\n",
    "pickle.dump(vectorizer, open(f'{MODEL_FOLDER_PATH}/vectorizer_sgc_classifier.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3149568",
   "metadata": {},
   "source": [
    "## Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = df_rests['ProductName'].value_counts().apply(np.sqrt).to_dict()\n",
    "model_logReg = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    # class_weight= weights\n",
    ")\n",
    "model_logReg.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_logReg = model_logReg.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_logReg)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_logReg, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_logReg, title='Confusion matrix for Rests')\n",
    "df_pred_top5_logReg = top5_accuracy_report(model_logReg, vectorizer, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd819b",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space of MultinomialNB model\n",
    "    pamams = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e+2, log=True),\n",
    "        'fit_prior': trial.suggest_categorical('fit_prior', [True, False])\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_multinomialNB = MultinomialNB(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_multinomialNB, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=300, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_multinomialNB = MultinomialNB(**best_params)\n",
    "best_model_multinomialNB.fit(X_train_encoded, y_train)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2540fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = df_rests['ProductName'].value_counts().apply(np.sqrt).to_dict()\n",
    "model_multinomialNB = best_model_multinomialNB\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_multinomialNB = model_multinomialNB.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_multinomialNB)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_multinomialNB, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_multinomialNB, title='Confusion matrix for Rests')\n",
    "df_pred_top5_multinomialNB = top5_accuracy_report(model_multinomialNB, vectorizer, X_test, y_test, pre_processed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
