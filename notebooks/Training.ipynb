{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b937898",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfc6d8-5b16-46c7-9c7d-20d869a41ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T09:32:43.980824Z",
     "start_time": "2023-10-16T09:32:42.963982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.config import *\n",
    "from src.helper_visualization import *\n",
    "from src.helper_pred import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cee41b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d43cb-9c69-4ee3-af91-93d06408057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_cleaned.xlsx'\n",
    "excel_file_train = f'{DATA_FOLDER_PATH_PROCESSED}/data_train.xlsx'\n",
    "df_train = pd.read_excel(excel_file_train)\n",
    "excel_file_test = f'{DATA_FOLDER_PATH_PROCESSED}/data_test.xlsx'\n",
    "df_test = pd.read_excel(excel_file_test)\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "hist_by_labels(df_train, 'Length', log=False, left=3.5, right=15.5)\n",
    "hist_by_labels(df_train, 'Product Name', log=True, right=25.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05769ab9",
   "metadata": {},
   "source": [
    "# Train/Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224206bb",
   "metadata": {},
   "source": [
    "Pipeline Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749006ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "TITLE_WORDS_MIN = 3\n",
    "TITLE_WORDS_MAX = 20\n",
    "LONGTAIL_CUTOFF = 200\n",
    "\n",
    "TEXT_COL = 'Title_Enhanced'\n",
    "TARGET_COL = 'Product Name'\n",
    "\n",
    "PRODUCT_SIZE_MAX_TRAIN = 2000\n",
    "PRODUCT_SIZE_MAX_TEST = 220\n",
    "MAX_FEATURES = 20000\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# create a scikit-learn transformer to remove the title with less than 3 words or more than 20 words\n",
    "class TitleLengthFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_words=TITLE_WORDS_MIN, max_words=TITLE_WORDS_MAX):\n",
    "        self.min_words = min_words\n",
    "        self.max_words = max_words\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df = df[df['Length'] >= self.min_words]\n",
    "        df = df[df['Length'] <= self.max_words]\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "# create a scikit-learn transformer to combine the products which have less than 200 samples into one product\n",
    "class LongTailCombiner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_samples=200, target_col=TARGET_COL):\n",
    "        self.min_samples = min_samples\n",
    "        self.target_col = target_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        counts = df[self.target_col].value_counts()\n",
    "        long_tails = counts.index[counts < self.min_samples]\n",
    "        mask = df[self.target_col].isin(long_tails)\n",
    "        df.loc[mask, self.target_col]='Long Tail'\n",
    "        return df\n",
    "\n",
    "# create a scikit-learn transformer to cap the number of samples for each product\n",
    "class SampleCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_samples=200, target_col=TARGET_COL):\n",
    "        self.max_samples = max_samples\n",
    "        self.target_col = target_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        counts = df[self.target_col].value_counts()\n",
    "        over_sampled = counts.index[counts > self.max_samples]\n",
    "        # mask = df[self.target_col].isin(over_sampled)\n",
    "        # df = df.drop(df[mask].sample(frac=1-self.max_samples/len(df)).index)\n",
    "        for item in over_sampled:\n",
    "            size = len(df[df[self.target_col]==item])\n",
    "            df = df.drop(df[df[self.target_col]==item].sample(frac=1-self.max_samples/size).index)\n",
    "        return df\n",
    "    \n",
    "    # create a scikit-learn pipeline to remove the title with less than 3 words or more than 20 words\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipleline_data_prep_train = Pipeline([\n",
    "    ('title_length_filter', TitleLengthFilter(min_words=TITLE_WORDS_MIN, max_words=TITLE_WORDS_MAX)),\n",
    "    ('long_tail_product_combiner', LongTailCombiner(min_samples=LONGTAIL_CUTOFF, target_col=TARGET_COL)),\n",
    "    ('sample_capper', SampleCapper(max_samples=PRODUCT_SIZE_MAX_TRAIN, target_col=TARGET_COL)),\n",
    "    # ('text_vectorizer', TextVectorizer(vectorizer=vectorizer))\n",
    "])\n",
    "\n",
    "pipleline_data_prep_test = Pipeline([\n",
    "    ('title_length_filter', TitleLengthFilter(min_words=TITLE_WORDS_MIN, max_words=TITLE_WORDS_MAX)),\n",
    "    ('long_tail_product_combiner', LongTailCombiner(min_samples=LONGTAIL_CUTOFF*12//100, target_col=TARGET_COL)),\n",
    "    ('sample_capper', SampleCapper(max_samples=PRODUCT_SIZE_MAX_TEST, target_col=TARGET_COL)),\n",
    "    # ('text_vectorizer', TextVectorizer(vectorizer=vectorizer))\n",
    "])\n",
    "display(pipleline_data_prep_train)\n",
    "display(pipleline_data_prep_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad29b0c",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be88b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pipleline_data_prep_train.fit_transform(df_train)\n",
    "hist_by_labels(train_data, 'Product Name', log=True, horizontal=True)\n",
    "train_data.info()\n",
    "\n",
    "test_data = pipleline_data_prep_test.fit_transform(df_test)\n",
    "hist_by_labels(test_data, 'Product Name', log=True, horizontal=True)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ee214-7530-4cbb-a8ef-c2f414d67a5c",
   "metadata": {},
   "source": [
    "# Model Baseline - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311dbb7-0451-4146-a451-2c7bd139af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciKit-Learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# Others\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdb179-508b-45f5-9951-94d9ee1b4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectorizer for text\n",
    "vectorizer_countvec = CountVectorizer(max_features=MAX_FEATURES, analyzer='word', ngram_range=(1, 2))\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=MAX_FEATURES, analyzer='word', ngram_range=(1, 2))\n",
    "\n",
    "X = df_train[TEXT_COL]\n",
    "vectorizer_countvec.fit(X)\n",
    "vectorizer_tfidf.fit(X)\n",
    "\n",
    "vectorizer = vectorizer_tfidf\n",
    "\n",
    "X_train = train_data[TEXT_COL]\n",
    "y_train = train_data[TARGET_COL]\n",
    "X_train_encoded = vectorizer.transform(X_train)\n",
    "\n",
    "X_test = test_data[TEXT_COL]\n",
    "X_test_encoded = vectorizer.transform(X_test)\n",
    "y_test = test_data[TARGET_COL]\n",
    "\n",
    "models = {\n",
    "    'SGDClassifier': SGDClassifier(max_iter=5000),\n",
    "    'SVC linear': SVC(kernel='linear'),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=5000),\n",
    "    # 'RandomForestClassifier': RandomForestClassifier(),\n",
    "    # 'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    # 'MultinomialNB': MultinomialNB(),\n",
    "    # 'SVC rbf': SVC(kernel='rbf'),\n",
    "}\n",
    "\n",
    "print('Baseline Score(s) of each model are ....')\n",
    "\n",
    "for model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        models[model], \n",
    "        X_train_encoded,\n",
    "        y_train, #the target\n",
    "        cv=5, \n",
    "        scoring='accuracy', # lease revise to the appropriate score\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f'Average score: \\033[94m{\"{:.4f}\".format(np.mean(cv_result))}\\033[0m by \\033[94m{model}\\033[0m.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12256a",
   "metadata": {},
   "source": [
    "# Hpyerparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916dcf5",
   "metadata": {},
   "source": [
    "## SGC Classifier (2min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae555272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the study if it exists\n",
    "study_name = 'sgd_classifier'\n",
    "storage_name = 'sqlite:///optuna_study.db'\n",
    "\n",
    "try:\n",
    "    optuna.delete_study(study_name=study_name, storage=storage_name)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e-3, log=True),\n",
    "        'eta0': trial.suggest_float('eta0', 1e-3, 1e-1, log=True),\n",
    "        'loss': trial.suggest_categorical('loss', ['log_loss', 'modified_huber']),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'adaptive']), #\n",
    "        'max_iter': 10000,\n",
    "        'random_state': 42\n",
    "        }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    sgd_classifier = SGDClassifier(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(sgd_classifier, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_sore = study.best_value\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_sore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143656da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the best Logistic Regression model\n",
    "best_model_sgc = SGDClassifier(**best_params)\n",
    "best_model_sgc.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict categories for the test data\n",
    "y_pred_sgc = best_model_sgc.predict(X_test_encoded)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_sgc)\n",
    "print(f'Accuracy: \\033[94m{accuracy:4f}\\033[0m')\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(classification_report(y_test, y_pred_sgc, digits=3))\n",
    "plot_confusion_matrix(y_test, y_pred_sgc, title='Confusion matrix for Rests')\n",
    "df_pred_top5_sgc = top5_accuracy_report(best_model_sgc, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "pickle.dump(best_model_sgc, open(f'{MODEL_FOLDER_PATH}/model_sgc_classifier.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_sgc_classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3149568",
   "metadata": {},
   "source": [
    "## Logistic Classification (5min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the study if it exists\n",
    "study_name = 'logReg'\n",
    "storage_name = 'sqlite:///optuna_study.db'\n",
    "try:\n",
    "    optuna.delete_study(study_name=study_name, storage=storage_name)\n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ea765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga', 'sag']),\n",
    "        'C': trial.suggest_float('C', 1e-2, 1e+2, log=True),\n",
    "        'penalty': 'l2',\n",
    "        'multi_class': 'ovr',\n",
    "        'max_iter': 50000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    logReg = LogisticRegression(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(logReg, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=5, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True,\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b371c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d197219",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the best Logistic Regression model\n",
    "best_model_logReg= LogisticRegression(**best_params)\n",
    "best_model_logReg.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_logReg = best_model_logReg.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_logReg)\n",
    "print(f'Accuracy: \\033[94m{accuracy:.4f}\\033[0m')\n",
    "\n",
    "report = classification_report(y_test, y_pred_logReg, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_logReg, title='Confusion matrix for Rests')\n",
    "df_pred_top5_logReg = top5_accuracy_report(best_model_logReg, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "pickle.dump(best_model_logReg, open(f'{MODEL_FOLDER_PATH}/model_logistic_regression.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_logistic_regression.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd819b",
   "metadata": {},
   "source": [
    "## MultinomialNB (2min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space of MultinomialNB model\n",
    "    pamams = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e+2, log=True),\n",
    "        'fit_prior': trial.suggest_categorical('fit_prior', [True, False])\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_multinomialNB = MultinomialNB(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_multinomialNB, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=250, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True,\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_multinomialNB = MultinomialNB(**best_params)\n",
    "best_model_multinomialNB.fit(X_train_encoded, y_train)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2540fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = df_rests['ProductName'].value_counts().apply(np.sqrt).to_dict()\n",
    "model_multinomialNB = best_model_multinomialNB\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_multinomialNB = model_multinomialNB.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_multinomialNB)\n",
    "print(f'Accuracy: \\033[94m{accuracy:4f}\\033[0m')\n",
    "\n",
    "report = classification_report(y_test, y_pred_multinomialNB, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_multinomialNB, title='Confusion matrix for Rests')\n",
    "df_pred_top5_multinomialNB = top5_accuracy_report(model_multinomialNB, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model and the vectorizer\n",
    "pickle.dump(best_model_multinomialNB, open(f'{MODEL_FOLDER_PATH}/model_multinomialNB.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_countvec, open(f'{MODEL_FOLDER_PATH}/vectorizer_multinomialNB.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa854f",
   "metadata": {},
   "source": [
    "## SVC Linear (>60min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user Optuna to tune the hyperparameters for SVC Linear\n",
    "study_name = 'SVC_linear'\n",
    "storage_name = 'sqlite:///optuna_study.db'\n",
    "\n",
    "# Clean up the study if it exists\n",
    "try:\n",
    "    optuna.delete_study(study_name=study_name, storage=storage_name)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a80439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'C': trial.suggest_float('C', 1, 1.2, log=True),\n",
    "        'max_iter': 50000,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_svc_linear = SVC(kernel='linear', probability=True, **pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_svc_linear, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=5, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_svc_linear = SVC(kernel='linear', **best_params)\n",
    "best_model_svc_linear.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f67fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_svc_linear = SVC(kernel='linear', probability=True, **best_params)\n",
    "# best_model_svc_linear = SVC(kernel='linear', probability=True)\n",
    "best_model_svc_linear.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_svc_linear = best_model_svc_linear.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_svc_linear)\n",
    "print(f'Accuracy: \\033[94m{accuracy:4f}\\033[0m')\n",
    "\n",
    "report = classification_report(y_test, y_pred_svc_linear, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_svc_linear, title='Confusion matrix for Rests')\n",
    "df_pred_top5_svc_linear = top5_accuracy_report(best_model_svc_linear, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model_svc_linear, open(f'{MODEL_FOLDER_PATH}/model_svc_linear.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_svc_linear.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9cfa54",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd09e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user Optuna to tune the hyperparameters for RandomForestClassifier\n",
    "\n",
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 4000, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "        # 'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        # 'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_random_forest = RandomForestClassifier(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_random_forest, X_train_encoded, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=10, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_model_random_forest = RandomForestClassifier(**best_params)\n",
    "best_model_random_forest.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_random_forest = best_model_random_forest.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(f'Accuracy: \\033[94m{accuracy:4f}\\033[0m')\n",
    "\n",
    "report = classification_report(y_test, y_pred_random_forest, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_random_forest, title='Confusion matrix for Rests')\n",
    "df_pred_top5_random_forest = top5_accuracy_report(best_model_random_forest, vectorizer_tfidf, X_test, y_test, pre_processed=True)\n",
    "\n",
    "pickle.dump(best_model_random_forest, open(f'{MODEL_FOLDER_PATH}/model_random_forest.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_random_forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b86c0",
   "metadata": {},
   "source": [
    "## Voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have three models, logistic regression, multinomialNB and svc_linear, we can use voting classifier to combine them together\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create a dictionary of the models\n",
    "estimators = [\n",
    "    ('logReg', best_model_logReg),\n",
    "    ('svc_linear', best_model_svc_linear),\n",
    "    ('sgc_classifier', best_model_sgc),\n",
    "]\n",
    "\n",
    "# Create a voting classifier\n",
    "voting = VotingClassifier(estimators, voting='soft', n_jobs=-1)\n",
    "\n",
    "# Fit the voting classifier to the training data\n",
    "voting.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_voting = voting.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "print(f'Accuracy: \\033[94m{accuracy:.4f}\\033[0m')\n",
    "\n",
    "report = classification_report(y_test, y_pred_voting, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_voting, title='Confusion matrix for Rests')\n",
    "\n",
    "df_pred_top5_voting = top5_accuracy_report(voting, vectorizer, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(voting, open(f'{MODEL_FOLDER_PATH}/model_voting.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_voting.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
