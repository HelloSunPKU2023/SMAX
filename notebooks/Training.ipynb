{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b937898",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfc6d8-5b16-46c7-9c7d-20d869a41ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T09:32:43.980824Z",
     "start_time": "2023-10-16T09:32:42.963982Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import concurrent.futures\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.config import *\n",
    "from src.helper_visualization import *\n",
    "# from src.helper_text import *\n",
    "# from src.helper_langID import *\n",
    "# from src.helper_translation import *\n",
    "from src.helper_pred import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728748cd",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cee41b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d43cb-9c69-4ee3-af91-93d06408057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_file = f'{DATA_FOLDER_PATH_PROCESSED}/data_cleaned.xlsx'\n",
    "excel_file_train = f'{DATA_FOLDER_PATH_PROCESSED}/data_augmented.xlsx'\n",
    "df_train = pd.read_excel(excel_file_train)\n",
    "excel_file_test = f'{DATA_FOLDER_PATH_PROCESSED}/data_test.xlsx'\n",
    "df_test = pd.read_excel(excel_file_test)\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "hist_by_labels(df_train, 'Length', log=False, left=2.5, right=15.5)\n",
    "# plot a square in red color on the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05769ab9",
   "metadata": {},
   "source": [
    "## Remove short Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa6138-b8e2-409b-9671-f4c6cbeacae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the titles with length less than 3 and more than 20\n",
    "# when the title is too short, it is either not useful or it is too obvious to be classified\n",
    "mask = (df_train['Length'] > 3) & (df_train['Length'] < 20)\n",
    "df_train = df_train[mask]\n",
    "hist_by_labels(df_train, 'Length', horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af51ac",
   "metadata": {},
   "source": [
    "## Combine the long tail into Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af37490",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_by_labels(df_train, 'Product Name', top=None, log=True, horizontal=True)\n",
    "hist_by_labels(df_test, 'Product Name', top=None, log=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f2f21-a4f0-4737-86d1-240d5b879bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the top 50 products and combine the rest into 'Others'\n",
    "cutoff = 1000\n",
    "\n",
    "product_counts = df_train['Product Name'].value_counts()\n",
    "product_top = product_counts.index[product_counts >= cutoff]\n",
    "product_others = product_counts.index[product_counts < cutoff]\n",
    "\n",
    "mask_others = df_train['Product Name'].isin(product_others)\n",
    "df_train.loc[mask_others,'Product Name']='Long Tail'\n",
    "\n",
    "mask_others = df_test['Product Name'].isin(product_others)\n",
    "df_test.loc[mask_others,'Product Name']='Long Tail'\n",
    "\n",
    "hist_by_labels(df_train, 'Product Name', log=True)\n",
    "hist_by_labels(df_test, 'Product Name', log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfd88b",
   "metadata": {},
   "source": [
    "## Balance Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea87d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the products with more than 5000 records, randomly select 4000 records for each product and put in a new dataframe df_cleaned_balanced, then keep the rest of the records in df_cleaned_test\n",
    "max_size = 5000\n",
    "\n",
    "df_train_balanced = pd.DataFrame()\n",
    "\n",
    "for product in df_train['Product Name'].unique():\n",
    "    df_product = df_train[df_train['Product Name'] == product]\n",
    "    if df_product.shape[0] > max_size:\n",
    "        df_product_balanced = df_product.sample(max_size).copy()\n",
    "    else:\n",
    "        df_product_balanced = df_product.copy()\n",
    "    df_train_balanced = pd.concat([df_train_balanced, df_product_balanced])\n",
    "\n",
    "print(df_train_balanced.info())\n",
    "\n",
    "hist_by_labels(df_train_balanced, 'Product Name', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 300\n",
    "\n",
    "df_test_balanced = pd.DataFrame()\n",
    "\n",
    "for product in df_test['Product Name'].unique():\n",
    "    df_product = df_test[df_test['Product Name'] == product]\n",
    "    if df_product.shape[0] > max_size:\n",
    "        df_product_balanced = df_product.sample(max_size).copy()\n",
    "    else:\n",
    "        df_product_balanced = df_product.copy()\n",
    "    df_test_balanced = pd.concat([df_test_balanced, df_product_balanced])\n",
    "\n",
    "print(df_test_balanced.info())\n",
    "\n",
    "\n",
    "hist_by_labels(df_test_balanced, 'Product Name', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496df7d-bb58-48ec-8549-b32d385a358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and testing for \n",
    "# a. cross validation\n",
    "# b. logistic regression, \n",
    "# c. SGC Classifier\n",
    "\n",
    "#import packages related to data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "column_name = 'Title_Translated'\n",
    "\n",
    "X = df_train[column_name]\n",
    "\n",
    "vectorizer_countvec = CountVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2))\n",
    "vectorizer_countvec.fit(X)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=20000, analyzer='word', ngram_range=(1, 2))\n",
    "vectorizer_tfidf.fit(X)\n",
    "\n",
    "X_train = df_train_balanced[column_name]\n",
    "y_train = df_train_balanced['Product Name']\n",
    "\n",
    "X_test = df_test_balanced[column_name]\n",
    "y_test = df_test_balanced['Product Name']\n",
    "\n",
    "X_train_countvec = vectorizer_countvec.transform(X_train)\n",
    "X_test_countvec = vectorizer_countvec.transform(X_test)\n",
    "\n",
    "X_train_tfidf = vectorizer_tfidf.transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "# vectorizer = vectorizer_countvec\n",
    "# X_train_encoded = X_train_countvec\n",
    "# X_test_encoded = X_test_countvec\n",
    "\n",
    "# vectorizer = vectorizer_tfidf\n",
    "# X_train_encoded = X_train_tfidf\n",
    "# X_test_encoded = X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab2640",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ee214-7530-4cbb-a8ef-c2f414d67a5c",
   "metadata": {},
   "source": [
    "## Model Baseline - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311dbb7-0451-4146-a451-2c7bd139af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Tuning\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdb179-508b-45f5-9951-94d9ee1b4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'SVC linear': SVC(kernel='linear'),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=5000),\n",
    "    'SGDClassifier': SGDClassifier(max_iter=5000),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    # 'SVC rbf': SVC(kernel='rbf'),\n",
    "}\n",
    "\n",
    "print('Baseline Score(s) of each model are ....')\n",
    "\n",
    "for model in models:\n",
    "    cv_result = cross_val_score(\n",
    "        models[model], \n",
    "        # X_train_countvec,\n",
    "        X_train_tfidf,\n",
    "        y_train, #the target\n",
    "        cv=5, \n",
    "        scoring='accuracy', # lease revise to the appropriate score\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f'Average score: \\033[94m{\"{:.4f}\".format(np.mean(cv_result))}\\033[0m by \\033[94m{model}\\033[0m.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Score(s) of each model are .... on augmented train dataset\n",
    "# Average score: 0.8539 by SGDClassifier.\n",
    "# Average score: 0.8556 by LogisticRegression.\n",
    "# Average score: 0.8856 by SVC linear.\n",
    "# Average score: 0.7962 by MultinomialNB.\n",
    "# Average score: 0.7978 by GradientBoostingClassifier.\n",
    "# Average score: 0.8716 by RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12256a",
   "metadata": {},
   "source": [
    "## Hpyerparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916dcf5",
   "metadata": {},
   "source": [
    "## SGC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd268f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'loss': trial.suggest_categorical('loss', ['log_loss', 'modified_huber']),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e+2, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'max_iter': 5000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    sgd_classifier = SGDClassifier(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(sgd_classifier, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=20, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_sgc = SGDClassifier(**best_params)\n",
    "best_model_sgc.fit(X_train_tfidf, y_train)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict categories for the test data\n",
    "y_pred_sgc = best_model_sgc.predict(X_test_tfidf)\n",
    "# Evaluate the classifier's performance\n",
    "print(classification_report(y_test, y_pred_sgc, digits=3))\n",
    "plot_confusion_matrix(y_test, y_pred_sgc, title='Confusion matrix for Rests')\n",
    "df_pred_top5_sgc = top5_accuracy_report(best_model_sgc, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "import pickle\n",
    "pickle.dump(best_model_sgc, open(f'{MODEL_FOLDER_PATH}/model_sgc_classifier.pkl', 'wb'))\n",
    "\n",
    "# export the vectorizer\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_sgc_classifier.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3149568",
   "metadata": {},
   "source": [
    "## Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ea765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga', 'sag']),\n",
    "        'C': trial.suggest_float('C', 1e-6, 1e+2, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2']),\n",
    "        'max_iter': 50000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    logReg = LogisticRegression(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(logReg, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=25, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True,\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the best Logistic Regression model\n",
    "best_model_logReg= LogisticRegression(**best_params)\n",
    "best_model_logReg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_logReg = best_model_logReg.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_logReg)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_logReg, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_logReg, title='Confusion matrix for Rests')\n",
    "df_pred_top5_logReg = top5_accuracy_report(best_model_logReg, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the best Logistic Regression model\n",
    "model_logReg= LogisticRegression(max_iter=5000)\n",
    "model_logReg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_logReg = model_logReg.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_logReg)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_logReg, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_logReg, title='Confusion matrix for Rests')\n",
    "df_pred_top5_logReg = top5_accuracy_report(model_logReg, vectorizer_countvec, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "import pickle\n",
    "pickle.dump(best_model_logReg, open(f'{MODEL_FOLDER_PATH}/model_logistic_regression.pkl', 'wb'))\n",
    "\n",
    "# export the vectorizer\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_logistic_regression.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd819b",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space of MultinomialNB model\n",
    "    pamams = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 1e+2, log=True),\n",
    "        'fit_prior': trial.suggest_categorical('fit_prior', [True, False])\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_multinomialNB = MultinomialNB(**pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_multinomialNB, X_train_countvec, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True,\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_multinomialNB = MultinomialNB(**best_params)\n",
    "best_model_multinomialNB.fit(X_train_countvec, y_train)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2540fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = df_rests['ProductName'].value_counts().apply(np.sqrt).to_dict()\n",
    "model_multinomialNB = best_model_multinomialNB\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_multinomialNB = model_multinomialNB.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_multinomialNB)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_multinomialNB, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_multinomialNB, title='Confusion matrix for Rests')\n",
    "df_pred_top5_multinomialNB = top5_accuracy_report(model_multinomialNB, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model and the vectorizer\n",
    "pickle.dump(best_model_multinomialNB, open(f'{MODEL_FOLDER_PATH}/model_multinomialNB.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_countvec, open(f'{MODEL_FOLDER_PATH}/vectorizer_multinomialNB.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa854f",
   "metadata": {},
   "source": [
    "## SVC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a80439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user Optuna to tune the hyperparameters for SVC Linear\n",
    "\n",
    "# Define an objective function to optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "\n",
    "    pamams = {\n",
    "        'C': trial.suggest_float('C', 1e-6, 1e+2, log=True),\n",
    "        'max_iter': 50000,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    # Create and train the SGD Classifier with suggested hyperparameters\n",
    "    model_svc_linear = SVC(kernel='linear', probability=True, **pamams)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    scores = cross_val_score(model_svc_linear, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=10, \n",
    "    n_jobs=-1, \n",
    "    show_progress_bar=True\n",
    "    )  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Create and train the best Logistic Regression model\n",
    "best_model_svc_linear = SVC(kernel='linear', **best_params)\n",
    "best_model_svc_linear.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_svc_linear = SVC(kernel='linear', probability=True, **best_params)\n",
    "best_model_svc_linear = SVC(kernel='linear', probability=True)\n",
    "best_model_svc_linear.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Evaluation\n",
    "y_pred_svc_linear = best_model_svc_linear.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_svc_linear)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_svc_linear, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_svc_linear, title='Confusion matrix for Rests')\n",
    "df_pred_top5_svc_linear = top5_accuracy_report(best_model_svc_linear, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model_svc_linear, open(f'{MODEL_FOLDER_PATH}/model_svc_linear.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_svc_linear.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b86c0",
   "metadata": {},
   "source": [
    "## Voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have three models, logistic regression, multinomialNB and svc_linear, we can use voting classifier to combine them together\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create a dictionary of the models\n",
    "estimators = [\n",
    "    ('logReg', best_model_logReg),\n",
    "    ('sgc_classifier', best_model_sgc),\n",
    "    ('svc_linear', best_model_svc_linear),\n",
    "    ('multinomialNB', best_model_multinomialNB)\n",
    "]\n",
    "\n",
    "# Create a voting classifier\n",
    "voting = VotingClassifier(estimators, voting='soft', n_jobs=-1)\n",
    "\n",
    "# Fit the voting classifier to the training data\n",
    "voting.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred_voting = voting.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred_voting, digits=3)\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_voting, title='Confusion matrix for Rests')\n",
    "\n",
    "df_pred_top5_voting = top5_accuracy_report(voting, vectorizer_tfidf, X_test, y_test, pre_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(voting, open(f'{MODEL_FOLDER_PATH}/model_voting.pkl', 'wb'))\n",
    "pickle.dump(vectorizer_tfidf, open(f'{MODEL_FOLDER_PATH}/vectorizer_voting.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
